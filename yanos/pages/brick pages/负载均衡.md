tag:: #大请求、#成加败减、#上下限、#可用性、#应用发布

-
- 静态负载均衡算法
	- **轮询与加权轮询**,轮询本身是一个非常简单的算法，用一句俗话讲，就是“排排坐，分果果”。也就是说，所有的候选节点轮流作为负载均衡的目标节点。
	- 平滑的加权轮询算法
	  >每个节点会有两个权重，初始权重（weight）和当前权重（currrentWeight）。算法的过程稍微有点复杂，每一次挑选节点都执行这些步骤。对每一个节点，执行 currrentWeight = currrentWeight + weight。挑选最大 currrentWeight 的节点作为目标节点。将目标节点的 currrentWeight 修改为 currrentWeight= currrentWeight - sum(weight)。
	- **随机与加权随机**,随机可以看作是随便挑选一个作为目标节点，加权随机则是利用不同的权重来设置选中的概率。权重越大，那么被选中的机会也就越大。
	- **哈希与一致性哈希**,哈希算法比较简单，一般就是选取请求里面某几个参数来计算一个哈希值，然后除以节点数量取余。这个过程几乎和随机一样，区别就在于随机算法里面用的是随机数，这里用的是根据参数计算出来的哈希值。
	  >>在性能非常苛刻的时候，我们会考虑使用本地缓存。但是使用本地缓存的数据一致性问题会非常严重，而我们可以尝试将一致性哈希负载均衡算法和本地缓存结合在一起，以提高缓存命中率，并且降低本地缓存的总体内存消耗。
	- 采用了一致性哈希负载均衡算法，依旧不能彻底解决数据一致性的问题，只能缓解一下（应用发布场景）
- 动态负载均衡算法
	- 我们公司用的是轮询来作为负载均衡。不过因为轮询没有实际查询服务端节点的负载，所以难免会出现偶发性的负载不均衡的问题。比如说我们之前发现线上的响应时间总体来说是非常均匀的，但是每隔一段时间就会出现响应时间特别慢的情况。而且时间间隔是不固定的，慢的程度也不一样，所以就很奇怪。后来我们经过排查之后，发现是因为当一个大请求落到一个节点的时候，它会占据大量的内存和 CPU。如果这时候再有请求打到同一个节点上，这部分请求的响应时间就会非常慢。**引子**
	- 我们稍微魔改了一下负载均衡算法，不再是单纯的轮询了。我们每天计算一批大客户，这部分大客户的请求会在负载均衡里面被打到专门的几个节点上。虽然大客户的请求依旧很慢，但是至少别的客户不会再受到他们的影响了。
	- 负载均衡算法有些时候用得好，是能够解决一些技术问题的，比如说缓存。
	- 实际上在工作中我们可以考虑根据调用结果来动态调整这个权重。